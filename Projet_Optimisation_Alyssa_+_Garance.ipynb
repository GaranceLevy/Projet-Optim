{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-4_ThE_eaRN"
   },
   "source": [
    "# Optimisation de la prédiction du risque de blessure pour athlètes de haut niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jzrq3GWYbq2r"
   },
   "source": [
    "**Questions pour Nelly Pustelnik**\n",
    "\n",
    "Nous avons trois grosses questions :\n",
    "\n",
    "1. La question du modèle : nous avons choisi d’utiliser une régression logistique pour modéliser la probabilité de blessure des athlètes. Cependant, ce modèle n’est peut-être pas le plus approprié pour notre problématique (du moins tel que nous l’avons formulée). De plus, il est possible que les variables explicatives disponibles ne soient pas suffisamment informatives pour prédire la survenue d’une blessure, phénomène qui peut dépendre de facteurs non observés dans nos données. Ainsi, bien que nos algorithmes convergent correctement, ils aboutissent à des performances prédictives très très faibles (à peine plus de 50%).\n",
    "\n",
    "2. Comme indiqué dans le Notebook, les données initiales sont fortement déséquilibrées : moins de 0,01 % des observations correspondent à des blessures.\n",
    "Pour pallier ce déséquilibre, nous avons adopté une stratégie de sous-échantillonnage :\n",
    "  * Nous conservons toutes les observations de blessure\n",
    "  * Nous tirons aléatoirement un sous-échantillon d’observations sans blessure afin d’obtenir un jeu de données contenant environ 20 % de blessés.\n",
    "  * Nous considérons ensuite ce sous-échantillon comme notre nouvel échantillon de travail pour l’ensemble du projet. Nous utilisons des poids dans la fonction de perte pour contre-carrer le déséquilibre restant.\n",
    "Notre question : ce choix méthodologique est-il acceptable?\n",
    "\n",
    "3. L'algorithme Chambolle-Pock. Nous rencontrons plusieurs difficultés avec l’implémentation de cet algorithme :\n",
    "* Nous ne parvenons pas à déterminer le prox de notre fonction $h$ telle que définie ci-dessous. La bibliothèque prox-repository propose un prox pour la fonction $\\log(1+\\exp(x))$, mais il ne semble pas directement applicable à notre cas, la fonction $h$ n’étant pas séparable en les coordonnées de $\\theta$.\n",
    "* En conséquence, nous avons pour l’instant remplacé le calcul du prox de $h$ par une descente de gradient.\n",
    "* Enfin, nous nous interrogeons sur le choix des paramètres $\\tau$ et $\\sigma$ dans l'algorithme de Chambolle-Pock : à part la contrainte $\\tau \\sigma \\leq 1$ avons nous d'autres conditions qui garantissent leur validité et leur stabilité dans notre contexte ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YERoKOVzeqlu"
   },
   "source": [
    "**Objectif :** prédire le risque de blessure d'un coureur sur un cycle d'entraînement.\n",
    "\n",
    "Les données : Notre base de données contient des données d'entraînement de 74 athlètes de haut niveau sur une période de 7 ans, avec des données qui sont au format hebdomadaire. La variable cible (blessure ou non) y est renseignée, ainsi que différentes covariables telles que :\n",
    "* Nombre de kilomètres\n",
    "* Intensité de l'entraînement\n",
    "* Type d'entraînement\n",
    "* Qualité perçue de la récupération\n",
    "* etc.\n",
    "\n",
    "[Source des données](https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/UWU9PV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUSqvmW9gLU9"
   },
   "source": [
    "## Modélisation du problème\n",
    "### Regression logistique\n",
    "**A voir** : peut-être qu'on veut rendre plus synthétique toute cette partie modélisation? Jsp à quel point ce document doit être court ou pas...\n",
    "\n",
    "On se donne un modèle de régression logistique:\n",
    "$$ P(Y = 1 \\mid X) = \\eta_{\\theta}(X) = \\frac{1}{1 + e^{-(X^\\top \\theta)}}. $$\n",
    "\n",
    "où le paramètre $X$ représente les données d'entraînement collectées sur la période de suivi sur lesquelles on ajoute une colonne de 1 pour capter une ordonnée à l'origine, et le paramètre $Y\n",
    " \\in \\{0,1\\}$ représente le fait de se blesser sur la période ($Y=1$) ou non $(Y=0)$.\n",
    "\n",
    " On se donne une règle de décision bayésienne à partir d'un vecteur d'observation $X$ (associé à une nouvelle semaine d'observation):\n",
    "$$\n",
    "\\begin{array}{c l}\n",
    "\\text{Prediction =  1} & \\text{si } \\eta_{\\theta}(X) \\geq \\frac{1}{2}, \\\\\n",
    "\\text{Prediction = 0} & \\text{sinon.}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Nous cherchons à estimer le vecteur $\\theta$ qui encode la relation de chacune des données au risque de blessure.\n",
    "\n",
    "Dans une approche statistique, on peut estimer ce paramètre en minimisant l'opposé de la log-vraisemblance conditionnelle, ce qui donne le problème d'optimisation suivant:\n",
    "$$\n",
    "\\hat{\\theta} = \\arg\\min_{\\theta \\in \\mathbb{R}^p} -\\sum_{i=1}^n Y_i \\log (\\eta_{\\theta}(X_i)) + (1-Y_i) \\log (1-\\eta_{\\theta}(X_i)).\n",
    "$$\n",
    "\n",
    "\n",
    "Mais quelques problèmes émergent avec cette méthode d'estimation:\n",
    "* Nous avons dans notre base de données  une prévalence nette des non-blessures sur les blessures: l'aléa entre prédire 1 et 0 n'est donc pas le même.\n",
    "* La parcimonie de notre modèle n'est pas garantie: on peut estimer des coefficients $\\theta_{j}$ en réalité pas très pertinents pour la prédiction du modèle.\n",
    "\n",
    "\n",
    "### Modélisation\n",
    "Pour pallier aux problèmes inhérents au modèle présenté précédemment, nous procédons de la manière suivante:\n",
    "* Ajouter des pondérations $\\omega_{0}$ et $\\omega_{1}$ aux différentes classes avec nécessairement $\\omega_{1} > \\omega_{0}$ (avec par ex: $\\omega_{1} = \\frac{n}{2n_{1}}$ et $\\omega_{0} = \\frac{n}{2n_{0}}$ qu'on peut par la suite renormaliser avec la règle $\\hat{\\omega_{i}} = \\frac{\\omega_{i}}{\\omega_{0} + \\omega_{1}})$\n",
    "\n",
    "* Ajouter une contrainte générale sur les $\\theta_{j}$ de la forme $\\sum_{j=1}^p |\\theta_{j}| \\leq \\alpha  $ (cela va permettre de forcer certains coefficients à 0 pour respecter la contrainte et de ne garder in fine qu'un nombre réduit de paramètres\n",
    "\n",
    "On obtient alors le nouveau problème d'optimisation:\n",
    "$$\n",
    "\\hat{\\theta} =\n",
    "\\arg\\min_{\\theta \\in \\mathbb{R}^p} -\\sum_{i=1}^n \\omega_{1} Y_i \\log (\\eta(X_i)) + \\omega_{0}(1-Y_i) \\log (1-\\eta(X_i)) , \\quad \\text{s.c. } \\sum_{j=1}^p |\\theta_j| \\leq \\alpha\n",
    "$$\n",
    "\n",
    "On peut alors construire le problème dual :\n",
    "\\begin{align*}\n",
    "\\max_{\\lambda \\ge 0} \\; \\min_{\\theta \\in \\mathbb{R}^p}\n",
    "\\mathcal{L}(\\theta, \\lambda) &=\n",
    "\\max_{\\lambda \\ge 0} \\; \\min_{\\theta \\in \\mathbb{R}^p}\n",
    "\\Bigg[\n",
    "- \\sum_{i=1}^n \\left[ \\omega_1 Y_i \\log (\\eta(X_i)) + \\omega_0 (1-Y_i) \\log (1-\\eta(X_i)) \\right]\n",
    "+ \\lambda \\|\\theta\\|_1 - \\lambda \\alpha\n",
    "\\Bigg] \\\\\n",
    "&=\n",
    "\\max_{\\lambda \\ge 0} \\; \\min_{\\theta \\in \\mathbb{R}^p}\n",
    "\\Bigg[\n",
    "- \\sum_{i=1}^n \\left[ \\omega_1 Y_i \\log (\\eta(X_i)) + \\omega_0 (1-Y_i) \\log (1-\\eta(X_i)) \\right]\n",
    "+ \\lambda \\|\\theta\\|_1\n",
    "\\Bigg]\n",
    "\\end{align*}\n",
    "\n",
    "Nous allons nous concentrer ici sur la résolution de la forme pénalisée. Notre problème d'optimisation final est donc le suivant:\n",
    "$$\n",
    "\\min_{\\theta \\in \\mathbb{R}^p}\n",
    "\\Bigg[\n",
    "- \\sum_{i=1}^n \\left[ \\omega_1 Y_i \\log (\\eta(X_i)) + \\omega_0 (1-Y_i) \\log (1-\\eta(X_i)) \\right]\n",
    "+ \\lambda \\|\\theta\\|_1\n",
    "\\Bigg]\n",
    "$$\n",
    "Que nous pourrions également formuler:\n",
    "$$ \\min_{\\theta \\in \\mathbb{R}^p} h(\\theta) + f(\\theta)\n",
    "$$\n",
    "\n",
    "Avec les fonctions $h$ et $f$ définies par:\n",
    "$$ \\begin{align}\n",
    "& h : \\quad && \\mathbb{R}^p \\to \\mathbb{R} \\\\\n",
    "& && \\theta \\mapsto - \\sum_{i=1}^n [\\omega_1 Y_i \\text{log}(\\eta_\\theta(X_i)) + \\omega_0(1-Y_i) \\text{log}(1-\\eta_\\theta(X_i))] \\\\\n",
    "& f : \\quad && \\mathbb{R}^p \\to \\mathbb{R} \\\\\n",
    "& && \\theta \\mapsto \\lambda \\| \\theta \\|_1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIJNcQTXksKp"
   },
   "source": [
    "###Hypothèse sous-jacente (un peu forte):\n",
    "\n",
    "On considère qu'il n'y a pas de différences intrinsèques entre coureurs (les effets marginaux de chaque variable sont identiques et les différences physiologiques de chaque coureur sont négligeables dans la modélisation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5WAEbIteJZh"
   },
   "outputs": [],
   "source": [
    "# Préambule\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    # No progress bar if tqdm is not installed\n",
    "    def tqdm(*args, **kwargs):\n",
    "        return args[0] # First argument is the iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alvWjOlmYMjV",
    "outputId": "2de3a6ac-4008-45be-e1a3-dc32fccd82c3"
   },
   "outputs": [],
   "source": [
    "pip install proxop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihNikthhd6Zo"
   },
   "source": [
    "## Prise en main des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWGZuCrxXIdb"
   },
   "source": [
    "###Description du jeu de données\n",
    "\n",
    "Avant de se lancer dans l'estimation, il faut comprendre comment est organisé notre base de données. Si l'on simplifie en se concentrant seulement sur le tableau qui constitue l'approche par semaine, nous obtenons la visualisation suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "kpB1xbEVdvhZ",
    "outputId": "4c9eb2fc-c143-4e6c-a94c-6e484477735b"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/content/week_approach_maskedID_timeseries.csv\")\n",
    "#df2 = pd.read_csv(\"week_approach_maskedID_timeseries.csv\")\n",
    "runners = {aid: group for aid, group in df2.groupby(\"Athlete ID\")}\n",
    "runner70_df2 = runners[70]\n",
    "runner70_df2.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dV8IYsiKaVvk"
   },
   "source": [
    "Ici, on se concentre seulement sur 10 semaines d'observations du 70ème athlète. On remarque que l'on a un jeu de variables \"courantes\" et un jeu de variables \"retardées\". Les variables retardées sont par exemple: \"rel total kms week 0_1\", \"rel rotal kms week 0_2\" et \"rel total kms week 1_2\". Celles-ci indiquent la variation de la charge d'entraînement entre deux semaines : la variation entre la semaine précédent l'observation et l'observation, la variation entre la semaine -2 précédent l'observation et l'observation ainsi que la variation entre les semaines -2 et -1 avant observation. Ces variables sont à interpréter en terme de pourcentage (1.05 équivaut +5% de charge d'entraînement). De plus, on observe des variables à extension: par exemple : nr sessions, nr sessions.1 et nr sessions.2 qui suivent en réalité la même logique (on comptabilise le nombre de session la semaine courante, la semaine -1 et la semaine-2). C'est donc un jeu de données très riche mais dont les lignes et les colonnes sont fortement corrélées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIlwYiTzIgcG"
   },
   "source": [
    "### Gestion de la base de données\n",
    "\n",
    "On se rend vite compte que notre modélisation est en fait mal posée: sur environ 43000 données on a seulement 575 occurrences de blessures. On ne pourra jamais échantillonner sur la totalité des données (c'est trop lourd) et lorsqu'on cherchera à sous-échantilloner il y aura très peu de chances d'obtenir des occurrences de blessures. On se propose de sous-échantilloner en gardant toutes les occurrences de blessures: pour s'assurer d'avoir quand même un échantillon de taille acceptable, on se propose de faire en sorte que la proportion de blessés représente 20% de l'échantillon. On pourra alors suivre notre raisonnement initial et adapter les pondérations $w_0$ et $w_1$ correspondantes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFLKXrMYNH5m",
    "outputId": "35c29ccd-a1fe-4b21-fbef-0b6e1c826e9b"
   },
   "outputs": [],
   "source": [
    "# proportion cible\n",
    "pi_ech_target = 0.2\n",
    "\n",
    "\n",
    "N_pop = len(df2)\n",
    "N1 = df2['injury'].sum()\n",
    "N0 = N_pop - N1\n",
    "pi_pop = N1 / N_pop\n",
    "\n",
    "# nombre total dans l'échantillon pour atteindre cette proportion\n",
    "N_ech = int(N1 / pi_ech_target)\n",
    "N0_ech = N_ech - N1\n",
    "\n",
    "# sous-échantillonnage\n",
    "df1 = df2[df2['injury'] == 1]\n",
    "df0 = df2[df2['injury'] == 0].sample(n=N0_ech, random_state=42)\n",
    "\n",
    "# concaténer les deux\n",
    "df_ech = pd.concat([df1, df0]).sample(frac=1, random_state=42)  # mélanger\n",
    "\n",
    "# nouvelle proportion\n",
    "pi_ech = df_ech['injury'].mean()\n",
    "\n",
    "#nouveaux poids\n",
    "w1 = len(df_ech)/(2*len(df1))\n",
    "w0 = len(df_ech)/(2*len(df0))\n",
    "\n",
    "print(f\"Taille de l'échantillon: {len(df_ech)}\")\n",
    "print(f\"w1 = {w1:.3f}, w0 = {w0:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W62ZxWL9xNh"
   },
   "source": [
    "# Etude des fonctions $h$ et $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hu1873XEnkCV"
   },
   "source": [
    "## La fonction $h$\n",
    "Les calculs suivants nous permettent d'obtenir le gradient de la fonction $h$ de notre problème telle que définie ci-dessus.\n",
    "\n",
    "$$h(\\theta) = - \\sum_{i=1}^n [\\omega_1 Y_i \\text{log}(\\eta_\\theta(X_i)) + \\omega_0(1-Y_i) \\text{log}(1-\\eta_\\theta(X_i))] $$\n",
    "\n",
    "La dérivée en $\\theta$ de $\\eta_{\\theta}(x)$ nous donne :\n",
    "$$\n",
    "\\nabla_{\\theta} \\eta_\\theta(x) = \\eta_\\theta(x)(1 - \\eta_\\theta(x))x\n",
    "$$\n",
    "D'où :\n",
    "* $$\n",
    "\\nabla_{\\theta} \\big[\\text{log}(\\eta_\\theta(x))\\big] = (1 - \\eta_\\theta(x))x\n",
    "$$\n",
    "* $$\n",
    "\\nabla_{\\theta} \\big[\\text{log}(1-\\eta_\\theta(x))\\big] = - \\eta_\\theta(x)x\n",
    "$$\n",
    "\n",
    "On obtient donc :\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla h (\\theta) & = - \\sum_{i = 1}^n \\big[ \\omega_1 Y_i (1 - \\eta_\\theta(X_i))X_i  -\\omega_0 (1-Y_i)\\eta_\\theta(X_i)X_i \\big] \\\\\n",
    "& = \\sum_{i = 1}^n \\big[ \\omega_0 (1-Y_i)\\eta_\\theta(X_i) - \\omega_1 Y_i (1 - \\eta_\\theta(X_i)) \\big]X_i\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9PgtC8Jmy1f"
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCCuMbxipTPj"
   },
   "source": [
    "Nous pouvons à présent définir les fonctions suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLWsfqwApYsx"
   },
   "outputs": [],
   "source": [
    "def eta(theta, x):\n",
    "    return 1/(1+np.exp(-x@theta))\n",
    "\n",
    "def h(theta, x, y, w0, w1):\n",
    "    n = eta(theta, x)\n",
    "    return -np.sum(w1 * y * np.log(n) + w0 * (1-y) * np.log(1-n))\n",
    "\n",
    "def grad_h(theta, x, y, w0, w1):\n",
    "    n = eta(theta, x)\n",
    "    coeff = w0*(1-y)*n - w1*y*(1-n)\n",
    "    return x.T@coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVmQdIV99tGc"
   },
   "source": [
    "### Etude de la nature $\\beta$-Lipschitz du gradient de $h$\n",
    "\n",
    "L'algorithme FISTA que nous allons implémenter contient un paramètre de pas, $\\gamma$, dont la valeur optimale est donnée pour $\\gamma \\in (0,2/\\beta) $ où $\\beta$ est la constante de Lipschitz pour le gradient de $h$.\n",
    "\n",
    "Après calcul, on trouve la valeur de $\\beta$ suivante:\n",
    "$$\n",
    "\\beta = \\frac{\\max(\\omega_0, \\omega_1)}{4} \\lambda_{max}\\left(\\sum^n_{i=1} X_iX_i^T \\right) = \\frac{\\max(\\omega_0, \\omega_1)}{4} \\lambda_{max} \\left( X^TX  \\right)\n",
    "$$\n",
    " où $\\lambda_{max}(A)$ désigne la plus grande valeur propre de $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W47RB9at_hj_"
   },
   "source": [
    "#### Premier calcul pour $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePn-ALcU_LZt",
    "outputId": "441108c0-35bc-485c-b2b2-f85a960a3b7e"
   },
   "outputs": [],
   "source": [
    "X = df_ech.drop(columns=[\"injury\"])\n",
    "eigvals = np.linalg.eigvalsh(X.T @ X)\n",
    "lambda_max = eigvals[-1]\n",
    "\n",
    "#valeur de beta\n",
    "beta = (max(w0, w1)/4)*lambda_max\n",
    "\n",
    "print(f\"Pas optimal calculé pour FISTA : {2/beta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7pO5VGOczBL"
   },
   "source": [
    "Avec le $\\beta$ donné, on obtient un pas optimal presque incalculable (de l'ordre de $10^{-17}$ !). Une méthode proposée est de standardiser (recentrer et réduire les variables) pour ne pas faire exploser le calcul de $\\lambda_{max}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoutN9jU_sEe"
   },
   "source": [
    "#### Standardisation des données et recalcul de $\\beta$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kA_s9bJGauHO",
    "outputId": "ca83a66a-0263-4a18-fadf-4ed5f1658d83"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "eigvals = np.linalg.eigvalsh(X_scaled.T @ X_scaled)\n",
    "lambda_bis = eigvals[-1]\n",
    "beta_b = (max(w0, w1)/4)*lambda_bis\n",
    "print(f\"Pas optimal calculé pour FISTA : {2/beta_b}\") # C'est mieux!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnvaE6FXpnw3"
   },
   "source": [
    "## La fonction $f$\n",
    "Nous définissons notre $f$ ainsi que sa fonction gradient, qui retourne un élément de la sous-différentielle de $f$, et son prox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mV4NyRwSqvdt"
   },
   "outputs": [],
   "source": [
    "def f(theta, lambd):\n",
    "  return lambd * np.sum(np.abs(theta))\n",
    "\n",
    "def grad_f(theta, lambd):\n",
    "  return lambd * np.sign(theta)\n",
    "\n",
    "def prox_f(wx, gamma):\n",
    "  return np.sign(wx) * np.maximum(np.abs(wx) - gamma, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wF5ZncO_N7JF"
   },
   "source": [
    "Nous pouvons à présent appliquer l'algorithme FISTA avec le pas $\\gamma$ donné par les bornes optimales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRr6qJpMA5Hj"
   },
   "source": [
    "# Préparation du terrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqiEmPbZBBMg"
   },
   "source": [
    "On sépare nos données en données train et test, en gardant le format standardisé pour $X$, on veillera à ajouter une colonne de 1 dans les variables \"x_training\" et \"x_validation\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JxRVjyVBXkj"
   },
   "outputs": [],
   "source": [
    "Y = df_ech[\"injury\"]\n",
    "x_training, x_validation, y_training, y_validation = train_test_split(\n",
    "    X_scaled, Y, test_size=0.25, random_state=42) # Défini quatre nouveaux ensembles qui sont nos données pour l'entrainement et pour le test.\n",
    "    # on laisse 1/4 des données de côté pour le test\n",
    "    # random_state pour la reproductibilité\n",
    "\n",
    "N = x_validation.shape[0]\n",
    "x_validation_int = np.hstack([x_validation, np.ones((N, 1))])\n",
    "N = x_training.shape[0]\n",
    "x_training_int = np.hstack([x_training, np.ones((N, 1))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OBy13uHCB4-"
   },
   "source": [
    "Fonctions (adaptées et récupérées du TP) utiles pour l'évaluation et la visualisation des différentes méthodes d'optimisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7af2200c"
   },
   "outputs": [],
   "source": [
    "def model(features, weights):\n",
    "    # features has shape N x K\n",
    "    # weights has shape K\n",
    "    # output has shape N\n",
    "    logits = features@weights\n",
    "    y_pred_prob = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "    return (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "def compose_title(title, subtitle=None): # Crée un titre complet pour les figures\n",
    "    subtitle = \"\" if subtitle is None else f\" ({subtitle})\"\n",
    "    return f\"{title}{subtitle}\"\n",
    "\n",
    "def disp_accuracy(weights, features, true_labels, subtitle=None): # Evalue la précision (accuracy) du modèle\n",
    "    result = model(features, weights)\n",
    "    errors = np.count_nonzero(result != true_labels) #compare les prédictions de model() aux vraies étiquettes\n",
    "    accuracy = 1 - errors / true_labels.size\n",
    "\n",
    "    # Précision conditionnelle : blessés (1) et non blessés (0)\n",
    "    mask_pos = (true_labels == 1)\n",
    "    mask_neg = (true_labels == 0)\n",
    "\n",
    "    # Nombre de vrais positifs / vrais négatifs\n",
    "    pred1 = np.count_nonzero((result == 1) & mask_pos) / np.count_nonzero(mask_pos)\n",
    "    pred0 = np.count_nonzero((result == 0) & mask_neg) / np.count_nonzero(mask_neg)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(true_labels, '*', label=\"Vraie valeur\")\n",
    "    plt.plot(result, '+', label=\"Valeur prédite\")\n",
    "    plt.xlabel(\"Athlète\")\n",
    "    plt.ylabel(\"Classe\")\n",
    "    plt.legend()\n",
    "    plt.title(compose_title(f\"Accuracy of {100*accuracy:.1f}% with {errors} errors\", subtitle))\n",
    "    plt.show() # Affiche un graphique comparant les vraies classes et les prédictions\n",
    "    # Affichage textuel\n",
    "    print(f\"Accuracy totale : {100*accuracy:.2f}%\")\n",
    "    print(f\"Accuracy sur les non-blessés (classe 0) : {100*pred0:.2f}%\")\n",
    "    print(f\"Accuracy sur les blessés (classe 1) : {100*pred1:.2f}%\")\n",
    "\n",
    "def disp_weight_variation(poids, subtitle=None): # Montre comment les poids du modèle changent au fil des itérations\n",
    "    displacement = np.linalg.norm(np.diff(poids, axis=0), axis=1) # Calcule la norme de la différence entre deux itérations successives\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.semilogy(displacement) # Trace les variations en échelle logarithmique\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Variation in the weight\")\n",
    "    plt.grid()\n",
    "    plt.title(compose_title(\"Weight variation\", subtitle))\n",
    "    plt.show()\n",
    "\n",
    "def disp_losses(losses, subtitle=None): # Trace les courbes de perte sur les itérations, en échelle log\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for name, loss in losses.items(): # dictionnaire permettant de comparer plusieurs méthodes sur le même graphique\n",
    "        plt.semilogy(loss, label=name)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title(compose_title(\"Loss\", subtitle))\n",
    "    plt.show()\n",
    "\n",
    "def disp_weight(x, sparse_tol=1e-4, subtitle=None): # visualiser les poids non nuls vs proches de zéro et calcul de sparsité\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    i = np.arange(len(x))\n",
    "    nonzeros = np.abs(x) > sparse_tol\n",
    "    sparsity = 1 - np.count_nonzero(nonzeros) / x.size\n",
    "    plt.plot(i[nonzeros], x[nonzeros], '.r', label=\"non zeros\")\n",
    "    plt.plot(i[~nonzeros], x[~nonzeros], '.g', label=f\"zeros (≤ {sparse_tol})\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Weight\")\n",
    "    plt.grid()\n",
    "    plt.title(compose_title(f\"Weight matrix with sparsity of {100*sparsity:.1f}%\", subtitle))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Fonction globale qui appelle toute les précédentes\n",
    "def disp_all_infos(current_method, theta_n, current_loss, lambd, sparse_tol=1e-4, other_losses=dict()):\n",
    "    print(\"Method:\", current_method) # Affiche nom de la méthode\n",
    "    print(\"Iterations:\", current_loss.size - 1) # Affiche nombre d'itérations\n",
    "    print(\"Last loss:\", current_loss[-1]) # Affiche dernière valeur de la perte\n",
    "    theta_star = theta_n[-1]\n",
    "    disp_losses(other_losses | {current_method: current_loss}) # Affiche courbe de perte\n",
    "    disp_weight_variation(theta_n) # Affiche variation des poids\n",
    "    disp_weight(theta_star, sparse_tol=sparse_tol, subtitle=f\"lambda = {lambd}\") # Affiche vecteur final des poids\n",
    "    disp_accuracy(theta_star, x_training_int, y_training, subtitle=\"training\") # Affiche accuracy sur les données d'entraînement\n",
    "    disp_accuracy(theta_star, x_validation_int, y_validation, subtitle=\"validation\") # Affiche accuracy sur les données de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cxF_EMtGeLv"
   },
   "source": [
    "# Approche 1 : FISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UKfd95-D892"
   },
   "outputs": [],
   "source": [
    "def algoFISTA(theta0, w0, w1, x, y, max_iter, gamma, lambd, tol=1e-5, a=4):\n",
    "    \"\"\" Algorithme FISTA\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    theta0: numpy.ndarray\n",
    "        Point de départ pour l'itération\n",
    "    x: numpy.ndarray\n",
    "        Notre échantillon de données d'entraînement, de taille (N, K)\n",
    "    y: numpy.ndarray\n",
    "        Variable binaire indiquant présence/absence de blessure, de taille (N,)\n",
    "    gamma: float\n",
    "        Pas de descente de l'algo FISTA step\n",
    "    max_iter: int\n",
    "        Nb maximal d'itérations\n",
    "    lambd: float\n",
    "        Paramètre de régularization\n",
    "    tol: float\n",
    "        Tolérance (critère d'arrêt)\n",
    "    a: float\n",
    "        Paramètre de l'lagorithme FISTA\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    theta_n: numpy.ndarray\n",
    "        Séquence de theta_n, de taille (nombre d'itérations + 1, K)\n",
    "    \"\"\"\n",
    "    tk = lambda k: (k + a - 1) / a\n",
    "    alphak = lambda k: (tk(k) - 1) / tk(k + 1)\n",
    "\n",
    "    theta_n = [theta0]\n",
    "    v = theta0\n",
    "\n",
    "    for k in tqdm(range(max_iter)):\n",
    "        g = grad_h(v, x, y, w0, w1)\n",
    "        theta_n.append(prox_f(v - gamma * g, lambd * gamma))\n",
    "        v = theta_n[-1] + alphak(k) * (theta_n[-1] - theta_n[-2])\n",
    "\n",
    "        if np.linalg.norm(theta_n[-1] - theta_n[-2]) <= tol:\n",
    "            break\n",
    "\n",
    "    return np.array(theta_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1ycMRRnaY56"
   },
   "source": [
    "##1er essai avec l'algo FISTA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cdca66604d124eecaefbf30fbd6661d2",
      "d3c8558d2f044665b56929c7f70ae6e1",
      "4ac325e73550460aaa67834400bcecfc",
      "b758bcb3080d435ea8bad72cefab189a",
      "9a8c351b9a7548c3b63cbf5eef106852",
      "5bbf7817c0a246458570a0daf92cbc52",
      "d686e2e9c92a413589ee429596e3406f",
      "85a2749244dd434699439e8f6886c2d6",
      "4834a97111554d4ebf9e1799f4749e85",
      "30ca048c876f41ce88166d5d4809c028",
      "42eb007589bb43e9ba3e746f8f4ad3ef"
     ]
    },
    "id": "R3jTCl1KQw9j",
    "outputId": "14f4820c-6a00-4bfb-a8fc-68ab4b85a747"
   },
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "gamma = 1.9/beta_b\n",
    "lambd = 1\n",
    "sparse_tol = 1e-2 # Tolerance when estimating sparsity of the weight vector\n",
    "\n",
    "N = x_training_int.shape[0]\n",
    "p = x_training_int.shape[1]\n",
    "\n",
    "theta0 = np.zeros(p)\n",
    "\n",
    "theta_n_fista_scaled = algoFISTA(theta0, w0=0.625, w1=2.5, x=x_training_int, y=y_training, max_iter=10_000, gamma=gamma, lambd=lambd)\n",
    "losses_fista = np.array([h(theta, x_training_int, y_training, 0.625, 2.5) + f(theta, lambd) for theta in theta_n_fista_scaled])\n",
    "\n",
    "disp_all_infos(\n",
    "    \"FISTA\",\n",
    "    theta_n_fista_scaled,\n",
    "    losses_fista,\n",
    "    lambd,\n",
    "    sparse_tol,\n",
    "    other_losses = {},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7DfBqqZGkZG"
   },
   "source": [
    "# Approche 2 : Chambolle - Pock\n",
    "voir réf: https://en.wikipedia.org/wiki/Chambolle%E2%80%93Pock_algorithm\n",
    "(à confirmer)\n",
    "\n",
    "Dans notre cas, on a $K = Id$, $G = h$ et $F = \\lambda \\| .\\|_1$ (Nous avons pris par défaut $\\theta = 1$ car il y a une garanti de convergence dans ce cas là, en s'assurant quand même que $\\tau\\sigma\\leq 1$)\n",
    "\n",
    "En gardant les mêmes fonctions $f$ et $h$ qu'auparavant, l'algorithme de Chambolle-Pock nécessite de connaître les fonctions $prox_{\\sigma f^*}$ et $prox_{\\tau h}$  pour $\\sigma$ et $\\tau$ des pas de descente constants. Nous n'avons pas de forme explicite pour le prox de $h$, toutefois comme nous avons vu que cette fonction est de gradient $\\beta$-lipschitz nous allons faire une mise à jour primale sur $\\nabla h$. Pour commencer nous definissons donc la fonction $prox_{\\sigma f^*}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xqh9cE9dkwbz"
   },
   "outputs": [],
   "source": [
    "def prox_fstar(x, lambd):\n",
    "  return np.clip(x, -lambd, lambd) #projection sur la boule infinie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ocp8thgxvZd"
   },
   "source": [
    "Quelles valeurs pour $\\tau$ et $\\sigma$ ? $\\tau$ doit peut-être être posé en fonction de $\\beta$, par exemple le pas théorique optimal de la descente de gradient à savoir $\\frac{1}{\\beta}$? Et ensuite on choisit $\\sigma = \\frac{1}{\\tau}$, comme ça on a bien $\\tau \\sigma \\leq 1$ ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h50HozLmiuAT"
   },
   "outputs": [],
   "source": [
    "def algoCP(x, y, theta0, theta_0, sigma, tau, max_iter, lambd, w0, w1, tol=1e-5):\n",
    "  \"\"\" Algorithme Chambolle-Pock\n",
    "\n",
    "  Paramètres\n",
    "  ----------\n",
    "  theta0: numpy.ndarray\n",
    "      Point de départ pour l'itération\n",
    "  theta_0: numpy.ndarray\n",
    "      Point de départ pour l'itération\n",
    "  x: numpy.ndarray\n",
    "      Notre échantillon de données d'entraînement, de taille (N, K)\n",
    "  y: numpy.ndarray\n",
    "      Variable binaire indiquant présence/absence de blessure, de taille (N,)\n",
    "  sigma, tau: float\n",
    "      Pas de descentes de l'algo Chambolle-Pock sur le pb primal et dual\n",
    "  max_iter: int\n",
    "      Nb maximal d'itérations\n",
    "  lambd: float\n",
    "      Paramètre de régularization\n",
    "  w0, w1: floats\n",
    "      Poids permettant d'équilibrer le problème dans la fonction grad_h\n",
    "  tol: float\n",
    "      Tolérance (critère d'arrêt)\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  theta_n: numpy.ndarray\n",
    "      Séquence de theta_n, de taille (nombre d'itérations + 1, K)\n",
    "  \"\"\"\n",
    "  #Initialisation\n",
    "  theta_n = [theta0] # x_n (j'écris ça pour l'instant pour m'y retrouver, on pourra supprimer après)\n",
    "  thetahat_n = [theta0] # x_bar_n\n",
    "  thetad_n = [theta_0] #y_n\n",
    "\n",
    "  for k in tqdm(range(max_iter)):\n",
    "    thetad_n.append(prox_fstar(thetad_n[-1] + sigma*thetahat_n[-1], lambd))\n",
    "    theta_n.append(theta_n[-1] - tau*(grad_h(theta_n[-1], x, y, w0, w1) + thetad_n[-1]))\n",
    "    thetahat_n.append(2*theta_n[-1] - theta_n[-2])\n",
    "\n",
    "    if np.linalg.norm(theta_n[-1] - theta_n[-2]) <= tol:\n",
    "            break\n",
    "  return np.array(theta_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ac341d951b87478bacdf1f341a7c95d3",
      "560eff93a5d64c329e162a190d9da67b",
      "dd80eabf547b4a538c15af39fa940939",
      "904e871f491b46dfb1d86cb3bf6895ce",
      "4c14cda4aceb48e7bb16e711e25ab13d",
      "5bd7ae2f10b24a4981810190f9d21812",
      "5f386c2587714ba2953c0f22db01fbad",
      "0fefe697abf3481cb87f18c49508c72d",
      "a3ff8a92c93a45a78137788edf24e2b0",
      "c5bde939f71c4ec6ab567074c0741fe1",
      "7ff748637cbd43c18079bc8dd487239a"
     ]
    },
    "id": "R1S2-xyUKeWw",
    "outputId": "17eb98d8-0eba-4d48-b4f3-b40768beea58"
   },
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "tau = 1/beta_b\n",
    "sigma = 0.9/tau\n",
    "lambd = 1\n",
    "sparse_tol = 1e-2 # Tolerance when estimating sparsity of the weight vector\n",
    "\n",
    "N = x_training_int.shape[0]\n",
    "p = x_training_int.shape[1]\n",
    "\n",
    "theta0 = np.zeros(p)\n",
    "theta_0 = np.zeros(p)\n",
    "\n",
    "theta_n_cp = algoCP(x=x_training_int, y=y_training, theta0 = theta0, theta_0 = theta_0, sigma = sigma, tau = tau, max_iter = 100_000, lambd=lambd, w0=0.625, w1=2.5, tol=1e-5)\n",
    "\n",
    "losses_cp = np.array([h(theta, x_training_int, y_training, 0.625, 2.5) + f(theta, lambd) for theta in theta_n_cp])\n",
    "\n",
    "disp_all_infos(\n",
    "    \"Chambolle-Pock\",\n",
    "    theta_n_cp,\n",
    "    losses_cp,\n",
    "    lambd,\n",
    "    sparse_tol,\n",
    "    other_losses = {},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDk4nXIKxUeN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsqRWeAIMg6"
   },
   "source": [
    "# Approche 3 : Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQhn6wd04UTI"
   },
   "source": [
    "Est-ce que pour l'approche Adam on doit garder le terme de régularization ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0dTtYAyBJB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhdC8sMVBL8b"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
